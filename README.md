# The Identification and Classification of the American Sign Language Fingerspelling Alphabet Using Leap Motion

Author: Emily Feng
Date: August 10, 2020
Professor: ZHANG Linxuan at Tsinghua University
Acknowledgements: Thank you to the writing help of CHEN Yan and XU Jinghui

Abstract. Communication with individuals with hearing disabilities in the
hearing world is often difficult without interpreters. To help these individuals
to be easily understood, this project focuses on using leap motion to translate
finger-spelled signs into written English. The project consists of building a
gesture library of the coordinate vectors of bones on the fingers and
classification of the hand transformation from an open palm position into the
gestures of 26 fingerspelling letters in the American Sign Language (ASL)
alphabet. Then, using Support Vector Classification (SVC), Extreme Gradient
Boosting (XGBoost), and Artificial Neural Networks (ANNs) algorithms to
classify and translate these signs. With a test set recorded in the gesture
library different from the learning set, this gesture recognition method
consisting of the coordinates of the bones has achieved an accuracy of 98%
with the XGBoost classification. In the future, rather than collecting more
data, coordinate vector calculation and image recognition can complement
each other so that the accuracy could be further increased, and more fit for
public application for the benefit of individuals with hearing disabilities.

Keywords: Leap Motion, Coordinate Vector Calculation, Support Vector
Classification, XGBoost, Artificial Neural Network

Paper: `ASL Alphabet Recognition Project.pdf`
